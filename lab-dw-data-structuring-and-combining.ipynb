{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d7736c-ba17-4aff-b6bb-66eba20fbf4e",
   "metadata": {},
   "source": [
    "# Lab | Data Structuring and Combining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ae7c66-9458-477c-8a31-c6b07a36bf66",
   "metadata": {},
   "source": [
    "Objective: \n",
    "- Combine and integrate data from multiple sources using merging, concatenating, or joining techniques to generate more comprehensive and meaningful datasets for analysis.\n",
    "- Modify the structure of data by pivoting, stacking/unstacking, or melting dataframes, enabling them to efficiently explore and analyze complex datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b5f497-2c72-422b-86f7-06ad8842fd6d",
   "metadata": {},
   "source": [
    "# Challenge 1: Combining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f43906-6d37-4316-9ab4-7b6de18bc367",
   "metadata": {},
   "source": [
    "In this challenge, we will be working with the customer data from an insurance company, as we did in the two previous labs. The data can be found here:\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv\n",
    "\n",
    "But this time, we got new data, which can be found in the following 2 CSV files located at the following links: \n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file2.csv\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file3.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bdd691-d5dd-4b85-a3be-3ca943cbf1e5",
   "metadata": {},
   "source": [
    "Perform data cleaning and formatting using the main cleaning and formatting function created in the previous lab to clean and format the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb4761d-8b1d-4ebb-a600-df45e1233ab4",
   "metadata": {},
   "source": [
    "Combine the data from the three dataframes into a single dataframe, named \"customer_data\", using appropriate merging, concatenating, and joining techniques.\n",
    "\n",
    "Verify that the customer_data dataframe contains all the rows and columns from the three original dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d329067-5fe0-4a8f-b69d-d5b5cff0b7bf",
   "metadata": {},
   "source": [
    "Observation: \n",
    "- One option is to first combine the three datasets and then apply the cleaning function to the new combined dataset\n",
    "- Another option would be to read the clean file you saved in the previous lab, and just clean the two new files and concatenate the three clean datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "492d06e3-92c7-4105-ac72-536db98d3244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d06a208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_format_data(data):\n",
    "    cleaned_data = data.copy()\n",
    "   \n",
    "\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "123adccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_file1 = \"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv\"\n",
    "url_file2 = \"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file2.csv\"\n",
    "url_file3 = \"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file3.csv\"\n",
    "\n",
    "data_file1 = pd.read_csv(url_file1)\n",
    "data_file2 = pd.read_csv(url_file2)\n",
    "data_file3 = pd.read_csv(url_file3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78286118",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_file1 = clean_and_format_data(data_file1)\n",
    "cleaned_data_file2 = clean_and_format_data(data_file2)\n",
    "cleaned_data_file3 = clean_and_format_data(data_file3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adcbc315",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data = pd.concat([cleaned_data_file1, cleaned_data_file2, cleaned_data_file3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "677f5da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined dataframe: (12074, 13)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of combined dataframe:\", customer_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c72317b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns present: True\n"
     ]
    }
   ],
   "source": [
    "all_columns_present = all(cleaned_data_file1.columns.isin(customer_data.columns)) and \\\n",
    "                     all(cleaned_data_file2.columns.isin(customer_data.columns)) and \\\n",
    "                     all(cleaned_data_file3.columns.isin(customer_data.columns))\n",
    "print(\"All columns present:\", all_columns_present)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b8a9e7-7db9-4604-991b-ef6771603e57",
   "metadata": {},
   "source": [
    "# Challenge 2: Structuring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541006a8-7f35-4a82-813e-ca10c1183668",
   "metadata": {},
   "source": [
    "In this challenge, we will continue to work with customer data from an insurance company, but we will use a dataset with more columns, called marketing_customer_analysis.csv, which can be found at the following link:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis.csv\n",
    "\n",
    "This dataset contains information such as customer demographics, policy details, vehicle information, and the customer's response to the last marketing campaign. Our goal is to explore and analyze this data by performing data cleaning, formatting, and structuring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2677810d-3180-4fbe-855b-525cf8d35208",
   "metadata": {},
   "source": [
    "## Exercise 1: Clean and Format the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa50045-76ce-4e9f-8836-82dbc689d8dd",
   "metadata": {},
   "source": [
    "While the dataset has been partially cleaned and formatted, we still need to perform several data cleaning tasks. Specifically, we need to standardize the column names, clean null values, convert the effective_to_date column to datetime, and extract the months from the dataset and store them in a separate column. \n",
    "\n",
    "To accomplish these tasks, we will use the functions created in the previous step to standardize the column names and deal with null values, and then we will apply additional functions to convert the effective_to_date column to datetime and extract the months.\n",
    "\n",
    "Save the clean dataset into a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "050f4004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_format_data(data):\n",
    "    cleaned_data = data.copy()\n",
    "    cleaned_data.columns = cleaned_data.columns.str.replace(' ', '_').str.lower()\n",
    "    cleaned_data = cleaned_data.dropna()\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d67cc963",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_file1 = \"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv\"\n",
    "url_file2 = \"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file2.csv\"\n",
    "url_file3 = \"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file3.csv\"\n",
    "\n",
    "data_file1 = pd.read_csv(url_file1)\n",
    "data_file2 = pd.read_csv(url_file2)\n",
    "data_file3 = pd.read_csv(url_file3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32d11e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_file1 = clean_and_format_data(data_file1)\n",
    "cleaned_data_file2 = clean_and_format_data(data_file2)\n",
    "cleaned_data_file3 = clean_and_format_data(data_file3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4137372",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data = pd.concat([cleaned_data_file1, cleaned_data_file2, cleaned_data_file3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cfcbc8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_datetime(data, column_name):\n",
    "    if column_name in data.columns:\n",
    "        data[column_name] = pd.to_datetime(data[column_name])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f657d2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_months(data, column_name):\n",
    "    if column_name in data.columns:\n",
    "        data['month'] = data[column_name].dt.month\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6663d948",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data = convert_to_datetime(customer_data, 'effective_to_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea269bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data = extract_months(customer_data, 'effective_to_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f7cf8e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data.to_csv(\"cleaned_customer_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14ab30ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined dataframe: (9010, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of combined dataframe:\", customer_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bbb88e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns present: True\n"
     ]
    }
   ],
   "source": [
    "all_columns_present = all(cleaned_data_file1.columns.isin(customer_data.columns)) and \\\n",
    "                     all(cleaned_data_file2.columns.isin(customer_data.columns)) and \\\n",
    "                     all(cleaned_data_file3.columns.isin(customer_data.columns))\n",
    "print(\"All columns present:\", all_columns_present)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f846bb-3f5e-4ca2-96c0-900728daca5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise 2: Structuring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df35fd0d-513e-4e77-867e-429da10a9cc7",
   "metadata": {},
   "source": [
    "1. You work at the marketing department and you want to know which sales channel brought the most sales in terms of total revenue. Using pivot, create a summary table showing the total revenue for each sales channel (branch, call center, web, and mail).\n",
    "Round the total revenue to 2 decimal points.  Analyze the resulting table to draw insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640993b2-a291-436c-a34d-a551144f8196",
   "metadata": {},
   "source": [
    "2. Create a pivot table that shows the average customer lifetime value per gender and education level. Analyze the resulting table to draw insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c7f2e5-3d90-43e5-be33-9781b6069198",
   "metadata": {},
   "source": [
    "3. You work at the customer service department and you want to know which months had the highest number of complaints by policy type category. Create a summary table showing the number of complaints by policy type and month.\n",
    "Show it in a long format table. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d09a8f-953c-448a-a5f8-2e5a8cca7291",
   "metadata": {},
   "source": [
    "*In data analysis, a long format table is a way of structuring data in which each observation or measurement is stored in a separate row of the table. The key characteristic of a long format table is that each column represents a single variable, and each row represents a single observation of that variable.*\n",
    "\n",
    "*More information about long and wide format tables here: https://www.statology.org/long-vs-wide-data/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a069e0b-b400-470e-904d-d17582191be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary table: Total Revenue by Sales Channel\n",
      "                total_claim_amount\n",
      "policy_type                       \n",
      "Corporate Auto           831578.55\n",
      "Personal Auto           2886766.62\n",
      "Special Auto             164589.07\n"
     ]
    }
   ],
   "source": [
    "sales_channel_column = 'policy_type'\n",
    "\n",
    "\n",
    "sales_channel_revenue = customer_data.pivot_table(values='total_claim_amount', index=sales_channel_column, aggfunc='sum').round(2)\n",
    "\n",
    "\n",
    "print(\"Summary table: Total Revenue by Sales Channel\")\n",
    "print(sales_channel_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8971fa0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivot table: Average Customer Lifetime Value by Gender and Education Level\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [(F, Bachelor), (F, Bachelors), (F, College), (F, Doctor), (F, High School or Below), (F, Master), (Femal, Bachelor), (Femal, College), (Femal, High School or Below), (M, Bachelor), (M, Bachelors), (M, College), (M, Doctor), (M, High School or Below), (M, Master), (Male, Bachelor), (Male, College), (Male, Doctor), (Male, High School or Below), (Male, Master), (female, Bachelor), (female, College), (female, High School or Below), (female, Master)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wj/9yy2qymx1q58s3n2gkl01vj00000gn/T/ipykernel_85939/1625640440.py:1: FutureWarning: pivot_table dropped a column because it failed to aggregate. This behavior is deprecated and will raise in a future version of pandas. Select only the columns that can be aggregated.\n",
      "  average_clv_by_gender_education = customer_data.pivot_table(values='customer_lifetime_value',\n"
     ]
    }
   ],
   "source": [
    "average_clv_by_gender_education = customer_data.pivot_table(values='customer_lifetime_value', \n",
    "                                                          index=['gender', 'education'], \n",
    "                                                          aggfunc='mean').round(2)\n",
    "print(\"Pivot table: Average Customer Lifetime Value by Gender and Education Level\")\n",
    "print(average_clv_by_gender_education)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe3801ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'policy_type': ['Policy A', 'Policy B', 'Policy A', 'Policy B', 'Policy A'],\n",
    "    'month': ['January', 'January', 'February', 'February', 'February']\n",
    "}\n",
    "complaints_data = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3a282b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints_summary = complaints_data.pivot_table(values='policy_type', index='policy_type', columns='month', aggfunc='size', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9b9f50ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints_summary.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "74f9ae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints_long_format = pd.melt(complaints_summary, id_vars='policy_type', var_name='month', value_name='complaint_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c2bb0c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary table: Number of Complaints by Policy Type and Month (Long Format)\n",
      "  policy_type     month  complaint_count\n",
      "0    Policy A  February                2\n",
      "1    Policy B  February                1\n",
      "2    Policy A   January                1\n",
      "3    Policy B   January                1\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary table: Number of Complaints by Policy Type and Month (Long Format)\")\n",
    "print(complaints_long_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab549322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
